import streamlit as st
import os
import requests
import json
import shutil
import streamlit.components.v1 as components 
from langchain_community.document_loaders import PyPDFLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_community.vectorstores import FAISS
from langchain_huggingface import HuggingFaceEmbeddings

# --- [1. ê¸°ë³¸ ì„¤ì • ë° ë¹„ë°€ë²ˆí˜¸] ---
st.set_page_config(page_title="ì„¤ë¹„ ë§¤ë‰´ì–¼ ì±—ë´‡", layout="wide", page_icon="ğŸ­")

# â˜… ê´€ë¦¬ì ë¹„ë°€ë²ˆí˜¸ ì„¤ì • (ì›í•˜ëŠ”ëŒ€ë¡œ ë³€ê²½í•˜ì„¸ìš”)
ADMIN_PASSWORD = "posco" 

# --- [2. CSS: ìŠ¤í¬ë¡¤ë°” ìœ ì§€ + UI ìŠ¤íƒ€ì¼] ---
st.markdown("""
    <style>
    /* 1. ì „ì²´ í°íŠ¸ */
    .stApp { font-family: 'Pretendard', sans-serif; }

    /* 2. ë©”ì¸ í™”ë©´ ìŠ¤í¬ë¡¤ ê°•ì œ í—ˆìš© */
    div[data-testid="stAppViewContainer"] {
        overflow-y: auto !important;
        overflow-x: hidden !important;
        height: 100vh !important;
    }

    /* 3. ì…ë ¥ì°½ ê°€ë¦¼ ë°©ì§€ ì—¬ë°± */
    .main .block-container {
        padding-bottom: 150px !important; 
        max-width: 100% !important;
    }

    /* 4. ì…ë ¥ì°½ ìŠ¤íƒ€ì¼ */
    div[data-testid="stBottom"] {
        background-color: white !important;
        z-index: 99999;
        border-top: 1px solid #ddd;
    }
    
    /* 5. ìŠ¤í¬ë¡¤ë°” ë””ìì¸ */
    ::-webkit-scrollbar {
        width: 12px !important;
        display: block !important;
    }
    ::-webkit-scrollbar-thumb {
        background-color: #bbb;
        border-radius: 6px;
    }
    
    /* 6. ì›ë¬¸ ë³´ê¸° í…ìŠ¤íŠ¸ë°•ìŠ¤ */
    .stTextArea textarea {
        font-family: 'Courier New', monospace;
        font-size: 0.9rem;
        background-color: #f8f9fa;
    }
    </style>
""", unsafe_allow_html=True)

# --- [3. ê²½ë¡œ ì„¤ì •] ---
DB_PATH = "manual_db"
MANUAL_DIR = "./manuals"
CACHE_DIR = "./manual_cache"
for d in [MANUAL_DIR, CACHE_DIR]:
    if not os.path.exists(d): os.makedirs(d)

# --- [4. ë°±ì—”ë“œ ë¡œì§] ---
@st.cache_resource
def get_embeddings():
    return HuggingFaceEmbeddings(model_name="./model")

def load_manual_db():
    embeddings = get_embeddings()
    if os.path.exists(DB_PATH):
        try:
            return FAISS.load_local(DB_PATH, embeddings, allow_dangerous_deserialization=True)
        except:
            return None
    return None

def update_vector_db():
    embeddings = get_embeddings()
    text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=100) # ì²­í¬ ì‚¬ì´ì¦ˆ ë¯¸ì„¸ ì¡°ì •
    
    current_files = [f for f in os.listdir(MANUAL_DIR) if f.endswith(".pdf")]
    cached = os.listdir(CACHE_DIR)
    
    # ì‚­ì œëœ íŒŒì¼ ìºì‹œ ì œê±°
    for c in cached:
        if c not in current_files: shutil.rmtree(os.path.join(CACHE_DIR, c))
            
    # ì‹ ê·œ íŒŒì¼ í•™ìŠµ
    files_to_process = [f for f in current_files if not os.path.exists(os.path.join(CACHE_DIR, f))]
    
    if files_to_process:
        bar = st.sidebar.progress(0)
        for idx, f in enumerate(files_to_process):
            st.toast(f"í•™ìŠµ ì¤‘: {f}")
            try:
                loader = PyPDFLoader(os.path.join(MANUAL_DIR, f))
                docs = loader.load_and_split(text_splitter)
                for doc in docs:
                    doc.metadata["source"] = f 
                    if "page" in doc.metadata: doc.metadata["page"] += 1
                
                if docs:
                    temp_db = FAISS.from_documents(docs, embeddings)
                    temp_db.save_local(os.path.join(CACHE_DIR, f))
            except Exception as e:
                st.error(f"ì˜¤ë¥˜ ({f}): {e}")
            bar.progress((idx + 1) / len(files_to_process))
        bar.empty()

    # DB ë³‘í•©
    valid_caches = [f for f in os.listdir(CACHE_DIR) if os.path.isdir(os.path.join(CACHE_DIR, f))]
    if not valid_caches:
        if os.path.exists(DB_PATH): shutil.rmtree(DB_PATH)
        return

    st.toast("DB í†µí•© ì¤‘...")
    base_db = FAISS.load_local(os.path.join(CACHE_DIR, valid_caches[0]), embeddings, allow_dangerous_deserialization=True)
    for cache_name in valid_caches[1:]:
        sub_db = FAISS.load_local(os.path.join(CACHE_DIR, cache_name), embeddings, allow_dangerous_deserialization=True)
        base_db.merge_from(sub_db)
    base_db.save_local(DB_PATH)
    st.success("ì—…ë°ì´íŠ¸ ì™„ë£Œ!")

def ask_posco_gpt(context, user_input):
    api_key = os.environ.get("POSCO_GPT_KEY")
    url = "http://aigpt.posco.net/gpgpta01-gpt/gptApi/personalApi"
    
    prompt = f"""
    ë‹¹ì‹ ì€ í¬ìŠ¤ì½” í“¨ì²˜ì—  ì„¤ë¹„ ìœ ì§€ë³´ìˆ˜ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
    ì•„ë˜ ì œê³µëœ [ë§¤ë‰´ì–¼ ë‚´ìš©]ë§Œì„ ë°”íƒ•ìœ¼ë¡œ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ë‹µë³€í•˜ì„¸ìš”.
    ë‚´ìš©ì— ì—†ëŠ” ì‚¬ì‹¤ì„ ì§€ì–´ë‚´ì§€ ë§ˆì„¸ìš”.
    
    [ë§¤ë‰´ì–¼ ë‚´ìš©]
    {context}
    
    [ì§ˆë¬¸]
    {user_input}
    
    [ë‹µë³€ í˜•ì‹]
    1. í•µì‹¬ ì¡°ì¹˜ ë‚´ìš© (ë²ˆí˜¸ ë§¤ê¸°ê¸°)
    2. ì°¸ê³  ë¬¸ì„œì™€ í˜ì´ì§€ (ì •í™•í•˜ê²Œ ëª…ì‹œ)
    """
    
    payload = {"messages": [{"role": "user", "content": prompt}], "model": "gpt-4o"}
    headers = {"Authorization": f"Bearer {api_key}", "Content-Type": "application/json"}
    try:
        response = requests.post(url, headers=headers, data=json.dumps(payload))
        return response.text
    except Exception as e:
        return f"GPT Error: {str(e)}"

# ìŠ¤í¬ë¡¤ ìë™ ì´ë™ (JS)
def scroll_to_bottom():
    js = """
    <script>
        var body = window.parent.document.querySelector(".main");
        if (body) { body.scrollTop = body.scrollHeight; }
    </script>
    """
    components.html(js, height=0, width=0)

# --- [5. ì‚¬ì´ë“œë°” ë¡œì§ (í•µì‹¬ ë³€ê²½)] ---
with st.sidebar:
    st.header("âš™ï¸ ì„¤ì •")
    
    # (1) ê²€ìƒ‰ ëŒ€ìƒ ì„ íƒ (ì •í™•ë„ í–¥ìƒìš©)
    file_list = [f for f in os.listdir(MANUAL_DIR) if f.endswith(".pdf")]
    search_options = ["ì „ì²´ ë§¤ë‰´ì–¼ ê²€ìƒ‰"] + file_list
    selected_manual = st.selectbox(
        "ê²€ìƒ‰ ëŒ€ìƒ ì„ íƒ", 
        search_options, 
        index=0,
        help="íŠ¹ì • ë§¤ë‰´ì–¼ì„ ì„ íƒí•˜ë©´ ë‹µë³€ì˜ ì •í™•ë„ê°€ ë†’ì•„ì§‘ë‹ˆë‹¤."
    )
    
    st.divider()
    
    # (2) ê´€ë¦¬ì ë¡œê·¸ì¸ (ë³´ì•ˆ ê¸°ëŠ¥)
    if "is_admin" not in st.session_state:
        st.session_state.is_admin = False

    if not st.session_state.is_admin:
        admin_input = st.text_input("ê´€ë¦¬ì ì•”í˜¸", type="password")
        if admin_input == ADMIN_PASSWORD:
            st.session_state.is_admin = True
            st.rerun()
    
    # (3) ê´€ë¦¬ì ì „ìš© ë©”ë‰´ (ë¡œê·¸ì¸ ì‹œì—ë§Œ ë³´ì„)
    if st.session_state.is_admin:
        st.success("ğŸ”“ ê´€ë¦¬ì ëª¨ë“œ")
        
        st.subheader("íŒŒì¼ ê´€ë¦¬")
        for f in file_list:
            c1, c2 = st.columns([0.8, 0.2])
            c1.text(f"{f}")
            if c2.button("x", key=f):
                os.remove(os.path.join(MANUAL_DIR, f))
                st.rerun()
        
        if st.button("ğŸ”„ DB ì—…ë°ì´íŠ¸ (í•™ìŠµ)", type="primary", use_container_width=True):
            update_vector_db()
            st.rerun()
            
        if st.button("ğŸšª ë¡œê·¸ì•„ì›ƒ"):
            st.session_state.is_admin = False
            st.rerun()
    else:
        st.info("ê´€ë¦¬ìë§Œ íŒŒì¼ì„ ìˆ˜ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")

    st.divider()
    if st.button("ğŸ§¹ ëŒ€í™” ë‚´ìš© ì§€ìš°ê¸°", use_container_width=True):
        st.session_state.messages = []
        st.rerun()

# --- [6. ë©”ì¸ ì±„íŒ… í™”ë©´] ---
if "messages" not in st.session_state:
    st.session_state.messages = []

# ëœë”© í˜ì´ì§€
if len(st.session_state.messages) == 0:
    st.markdown("""
        <div style="text-align: center; margin-top: 15vh;">
            <div style="font-size: 5rem; margin-bottom: 20px;">ğŸ­</div>
            <h1 style="color: #005eb8;">POSCO FUTURE M<br>Smart Assistant</h1>
            <p style="color: #555; font-size: 1.2rem;">ì„¤ë¹„ ë§¤ë‰´ì–¼ ë° íŠ¸ëŸ¬ë¸”ìŠˆíŒ… AI</p>
        </div>
    """, unsafe_allow_html=True)
else:
    st.caption("ğŸš€ POSCO FUTURE M ì„¤ë¹„ ë§¤ë‰´ì–¼ ì±—ë´‡")
    for msg in st.session_state.messages:
        with st.chat_message(msg["role"]):
            st.markdown(msg["content"])

# ì…ë ¥ì°½
if prompt := st.chat_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”..."):
    st.session_state.messages.append({"role": "user", "content": prompt})
    st.rerun()

# ë‹µë³€ ë¡œì§ (í•„í„°ë§ ì ìš©)
if st.session_state.messages and st.session_state.messages[-1]["role"] == "user":
    vectorstore = load_manual_db()
    
    if vectorstore:
        with st.chat_message("assistant"):
            with st.spinner(f"'{selected_manual}'ì—ì„œ ê²€ìƒ‰ ì¤‘..."):
                
                # â˜… í•µì‹¬: í•„í„°ë§ ë¡œì§ ì¶”ê°€
                # ì „ì²´ ê²€ìƒ‰ì´ ì•„ë‹ˆë©´ metadataì˜ 'source'ê°€ ì¼ì¹˜í•˜ëŠ” ê²ƒë§Œ ê²€ìƒ‰í•¨
                search_kwargs = {}
                if selected_manual != "ì „ì²´ ë§¤ë‰´ì–¼ ê²€ìƒ‰":
                    search_kwargs["filter"] = {"source": selected_manual}
                
                # ê²€ìƒ‰ ìˆ˜í–‰
                try:
                    docs = vectorstore.similarity_search(
                        st.session_state.messages[-1]["content"], 
                        k=5, 
                        **search_kwargs
                    )
                except Exception as e:
                    st.error("ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. DBë¥¼ ì—…ë°ì´íŠ¸í•´ì£¼ì„¸ìš”.")
                    docs = []

                if not docs:
                    answer = f"âš ï¸ '{selected_manual}' ë‚´ì—ì„œ ê´€ë ¨ ë‚´ìš©ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë‹¤ë¥¸ ë§¤ë‰´ì–¼ì„ ì„ íƒí•˜ê±°ë‚˜ ì§ˆë¬¸ì„ êµ¬ì²´ì ìœ¼ë¡œ í•´ì£¼ì„¸ìš”."
                    sources = []
                    full_context = ""
                else:
                    context_parts = []
                    sources = set()
                    for d in docs:
                        content = d.page_content 
                        src = d.metadata.get('source', 'Unknown')
                        page = d.metadata.get('page', 0)
                        context_parts.append(f"ğŸ“„ [íŒŒì¼: {src} | p.{page}]\n{content}")
                        sources.add(f"{src} (p.{page})")
                    
                    full_context = "\n\n".join(context_parts)
                    answer = ask_posco_gpt(full_context, st.session_state.messages[-1]["content"])
                
                st.markdown(answer)
                
                if sources:
                    st.divider()
                    st.caption(f"**ğŸ“š ì°¸ì¡° ë¬¸ì„œ:** {', '.join(sources)}")
                    with st.expander("ğŸ” ì›ë¬¸ ë³´ê¸°"):
                        st.text_area("ì›ë¬¸", value=full_context, height=300, label_visibility="collapsed")
                
                st.session_state.messages.append({"role": "assistant", "content": answer})
                scroll_to_bottom()
    else:
        st.error("í•™ìŠµëœ DBê°€ ì—†ìŠµë‹ˆë‹¤. ê´€ë¦¬ìì—ê²Œ ë¬¸ì˜í•˜ì—¬ DBë¥¼ ì—…ë°ì´íŠ¸í•˜ì„¸ìš”.")
        st.session_state.messages.append({"role": "assistant", "content": "DBê°€ ì—†ìŠµë‹ˆë‹¤."})

# í•˜ë‹¨ ì—¬ë°± í™•ë³´
st.markdown("<div style='height: 100px;'></div>", unsafe_allow_html=True)
if len(st.session_state.messages) > 0:
    scroll_to_bottom()
