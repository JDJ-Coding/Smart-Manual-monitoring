import sys
import os

# 1. íŒŒì´ì¬ì´ ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì°¾ëŠ” ëª¨ë“  ê°€ëŠ¥ì„± ìˆëŠ” ê²½ë¡œë¥¼ ê°•ì œë¡œ ì¶”ê°€
paths = [
    r"C:\Users\ì¥ë•ì§„\AppData\Local\Programs\Python\Python313\Lib\site-packages",
    r"C:\Users\ì¥ë•ì§„\AppData\Roaming\Python\Python313\site-packages",
    os.path.join(os.getcwd(), ".venv", "Lib", "site-packages")
]

for p in paths:
    if p not in sys.path:
        sys.path.append(p)

# ì´ì œì„œì•¼ ì›ë˜ ì½”ë“œ ì‹œì‘

import streamlit as st
import os
import requests
import json
from langchain_community.document_loaders import PyPDFLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_community.vectorstores import FAISS
from langchain_huggingface import HuggingFaceEmbeddings

# --- [ì„¤ì • ë° ì´ˆê¸°í™”] ---
DB_PATH = "manual_db"
MANUAL_DIR = "./manuals"
if not os.path.exists(MANUAL_DIR): os.makedirs(MANUAL_DIR)

# 1. ë¬´ë£Œ ì˜¤í”ˆì†ŒìŠ¤ í•œêµ­ì–´ ì„ë² ë”© ëª¨ë¸ (CPUì—ì„œë„ ì˜ ëŒì•„ê°‘ë‹ˆë‹¤)
@st.cache_resource
def get_embeddings():
    return HuggingFaceEmbeddings(model_name="jhgan/ko-sroberta-multitask")

# 2. ë²¡í„° DB ë¡œë“œ ë˜ëŠ” ìƒì„± í•¨ìˆ˜
def load_manual_db():
    embeddings = get_embeddings()
    if os.path.exists(DB_PATH):
        return FAISS.load_local(DB_PATH, embeddings, allow_dangerous_deserialization=True)
    return None

# 3. POSCO GPT í˜¸ì¶œ í•¨ìˆ˜
def ask_posco_gpt(context, user_input):
    api_key = os.environ.get("POSCO_GPT_KEY")
    url = "http://aigpt.posco.net/gpgpta01-gpt/gptApi/personalApi"
    
    prompt = f"ì•„ë˜ ë§¤ë‰´ì–¼ ë‚´ìš©ì„ ì°¸ê³ í•˜ì—¬ ë‹µë³€í•˜ì„¸ìš”.\n\n[ë§¤ë‰´ì–¼ ë‚´ìš©]\n{context}\n\n[ì§ˆë¬¸]\n{user_input}"
    
    payload = {
        "messages": [
            {"role": "system", "content": "ë„ˆëŠ” í¬ìŠ¤ì½” í“¨ì²˜ì— ì˜ ì„¤ë¹„ ì „ë¬¸ê°€ì•¼. ë§¤ë‰´ì–¼ì— ê·¼ê±°í•˜ì—¬ ì •í™•í•˜ê²Œ ë‹µë³€í•´."},
            {"role": "user", "content": prompt}
        ],
        "model": "gpt-4o"
    }
    headers = {"Authorization": f"Bearer {api_key}", "Content-Type": "application/json"}
    
    response = requests.post(url, headers=headers, data=json.dumps(payload))
    # ì‘ë‹µ í˜•íƒœê°€ JSONì´ë¼ë©´ response.json().get('choices')[0]['message']['content'] ë“±ìœ¼ë¡œ ìˆ˜ì • í•„ìš”
    return response.text

# --- [UI ë ˆì´ì•„ì›ƒ] ---
st.set_page_config(page_title="ì„¤ë¹„ ë§¤ë‰´ì–¼ ì–´ì‹œìŠ¤í„´íŠ¸", layout="wide")

# ì‚¬ì´ë“œë°”: ë§¤ë‰´ì–¼ ê´€ë¦¬
with st.sidebar:
    st.header("ğŸ“‚ ë§¤ë‰´ì–¼ ê´€ë¦¬")
    files = os.listdir(MANUAL_DIR)
    st.write(f"í˜„ì¬ ë“±ë¡ëœ íŒŒì¼: {len(files)}ê°œ")
    for f in files[:10]: st.text(f"â€¢ {f}")
    
    if st.button("ğŸ”„ ì „ì²´ ë§¤ë‰´ì–¼ ìƒˆë¡œê³ ì¹¨/í•™ìŠµ"):
        with st.spinner("ë§¤ë‰´ì–¼ ë¶„ì„ ì¤‘... (ì•½ ìˆ˜ ë¶„ ì†Œìš”)"):
            all_docs = []
            splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)
            for f in files:
                if f.endswith(".pdf"):
                    loader = PyPDFLoader(os.path.join(MANUAL_DIR, f))
                    all_docs.extend(loader.load_and_split(splitter))
            
            vectorstore = FAISS.from_documents(all_docs, get_embeddings())
            vectorstore.save_local(DB_PATH)
            st.success("í•™ìŠµ ì™„ë£Œ!")
            st.rerun()

# ë©”ì¸ í™”ë©´: ì±„íŒ… ì¸í„°í˜ì´ìŠ¤
st.title("ğŸ¤– POSCO í“¨ì²˜ì—  ì„¤ë¹„ ë§¤ë‰´ì–¼ ì±—ë´‡")
st.caption("ì¥ì¹˜ ëª¨ë¸ëª…ê³¼ ê³ ì¥ ì¦ìƒì„ ì…ë ¥í•˜ë©´ ë§¤ë‰´ì–¼ì—ì„œ ì •ë‹µì„ ì°¾ì•„ë“œë¦½ë‹ˆë‹¤.")

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™” (ì±„íŒ… ê¸°ë¡ ì €ì¥ìš©)
if "messages" not in st.session_state:
    st.session_state.messages = []

# ê¸°ì¡´ ëŒ€í™” í‘œì‹œ
for msg in st.session_state.messages:
    with st.chat_message(msg["role"]):
        st.markdown(msg["content"])

# ì§ˆë¬¸ ì…ë ¥
if prompt := st.chat_input("ì—ëŸ¬ ì½”ë“œë‚˜ ì ê²€ ë°©ë²•ì„ ë¬¼ì–´ë³´ì„¸ìš”."):
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    # ë‹µë³€ ìƒì„± ë¡œì§
    vectorstore = load_manual_db()
    if vectorstore:
        # 1. ê²€ìƒ‰ (ìœ ì‚¬ ë¬¸ì„œ 3ê°œ)
        docs = vectorstore.similarity_search(prompt, k=3)
        
        # 2. ì»¨í…ìŠ¤íŠ¸ì™€ ì¶œì²˜ ì •ë¦¬
        context_list = []
        sources = set()
        for d in docs:
            context_list.append(d.page_content)
            # ë©”íƒ€ë°ì´í„°ì—ì„œ íŒŒì¼ëª…ê³¼ í˜ì´ì§€ ì¶”ì¶œ
            source_info = f"{d.metadata.get('source', 'Unknown')} (P. {d.metadata.get('page', '0') + 1})"
            sources.add(source_info)
        
        context_text = "\n---\n".join(context_list)
        
        # 3. AI í˜¸ì¶œ
        with st.chat_message("assistant"):
            with st.spinner("ë§¤ë‰´ì–¼ì„ í™•ì¸í•˜ê³  ìˆìŠµë‹ˆë‹¤..."):
                answer = ask_posco_gpt(context_text, prompt)
                
                full_response = f"{answer}\n\n---\n**ğŸ“ ì°¸ê³  ì¶œì²˜:**\n" + "\n".join([f"- {s}" for s in sources])
                st.markdown(full_response)
                st.session_state.messages.append({"role": "assistant", "content": full_response})
    else:
        st.error("ì‚¬ì´ë“œë°”ì—ì„œ 'ì „ì²´ ë§¤ë‰´ì–¼ ìƒˆë¡œê³ ì¹¨'ì„ ë¨¼ì € ëˆŒëŸ¬ì£¼ì„¸ìš”!")