import streamlit as st
import os
import requests
import json
import shutil
import time  # time ëª¨ë“ˆ ì¶”ê°€
import streamlit.components.v1 as components 
from langchain_community.document_loaders import PyPDFLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_community.vectorstores import FAISS
from langchain_huggingface import HuggingFaceEmbeddings

# --- [1. ê¸°ë³¸ ì„¤ì •] ---
st.set_page_config(page_title="ì„¤ë¹„ ë§¤ë‰´ì–¼ ì±—ë´‡", layout="wide", page_icon="ğŸ­")
ADMIN_PASSWORD = "posco" 

# --- [2. CSS ìŠ¤íƒ€ì¼] ---
st.markdown("""
    <style>
    .stApp { font-family: 'Pretendard', sans-serif; }
    div[data-testid="stAppViewContainer"] { overflow-y: auto !important; overflow-x: hidden !important; height: 100vh !important; }
    .main .block-container { padding-bottom: 150px !important; max-width: 100% !important; }
    div[data-testid="stBottom"] { background-color: white !important; z-index: 99999; border-top: 1px solid #ddd; }
    ::-webkit-scrollbar { width: 12px !important; display: block !important; }
    ::-webkit-scrollbar-thumb { background-color: #bbb; border-radius: 6px; }
    .stTextArea textarea { font-family: 'Courier New', monospace; font-size: 0.9rem; background-color: #f8f9fa; }
    </style>
""", unsafe_allow_html=True)

# --- [3. ê²½ë¡œ ì„¤ì •] ---
DB_PATH = "manual_db"
MANUAL_DIR = "./manuals"
CACHE_DIR = "./manual_cache"
for d in [MANUAL_DIR, CACHE_DIR]:
    if not os.path.exists(d): os.makedirs(d)

# --- [4. í•¨ìˆ˜ ë¡œì§] ---
@st.cache_resource
def get_embeddings():
    return HuggingFaceEmbeddings(model_name="./model")

def load_manual_db():
    embeddings = get_embeddings()
    if os.path.exists(DB_PATH):
        try:
            return FAISS.load_local(DB_PATH, embeddings, allow_dangerous_deserialization=True)
        except:
            return None
    return None

def update_vector_db():
    embeddings = get_embeddings()
    
    # â˜… [ì¤‘ìš”] í‘œ ì¸ì‹ì„ ìœ„í•´ Chunk Size ëŒ€í­ ì¦ê°€
    text_splitter = RecursiveCharacterTextSplitter(
        chunk_size=1200, 
        chunk_overlap=300,
        separators=["\n\n", "\n", " ", ""]
    )
    
    current_files = [f for f in os.listdir(MANUAL_DIR) if f.endswith(".pdf")]
    
    # ê¸°ì¡´ ìºì‹œ ì¤‘ ì‚­ì œëœ íŒŒì¼ ì •ë¦¬
    cached = os.listdir(CACHE_DIR)
    for c in cached:
        if c not in current_files: 
            shutil.rmtree(os.path.join(CACHE_DIR, c), ignore_errors=True)
            
    files_to_process = [f for f in current_files if not os.path.exists(os.path.join(CACHE_DIR, f))]
    
    if files_to_process:
        bar = st.sidebar.progress(0)
        status = st.sidebar.empty()
        for idx, f in enumerate(files_to_process):
            status.text(f"í•™ìŠµ ì¤‘... {f}")
            try:
                loader = PyPDFLoader(os.path.join(MANUAL_DIR, f))
                docs = loader.load_and_split(text_splitter)
                for doc in docs:
                    doc.metadata["source"] = f 
                    if "page" in doc.metadata: doc.metadata["page"] += 1
                
                if docs:
                    temp_db = FAISS.from_documents(docs, embeddings)
                    temp_db.save_local(os.path.join(CACHE_DIR, f))
            except Exception as e:
                st.error(f"ì˜¤ë¥˜ ({f}): {e}")
            bar.progress((idx + 1) / len(files_to_process))
        bar.empty()
        status.empty()

    # DB ë³‘í•©
    valid_caches = [f for f in os.listdir(CACHE_DIR) if os.path.isdir(os.path.join(CACHE_DIR, f))]
    if not valid_caches:
        if os.path.exists(DB_PATH): shutil.rmtree(DB_PATH, ignore_errors=True)
        return

    base_db = FAISS.load_local(os.path.join(CACHE_DIR, valid_caches[0]), embeddings, allow_dangerous_deserialization=True)
    for cache_name in valid_caches[1:]:
        sub_db = FAISS.load_local(os.path.join(CACHE_DIR, cache_name), embeddings, allow_dangerous_deserialization=True)
        base_db.merge_from(sub_db)
    base_db.save_local(DB_PATH)

def ask_posco_gpt(context, user_input):
    api_key = os.environ.get("POSCO_GPT_KEY")
    url = "http://aigpt.posco.net/gpgpta01-gpt/gptApi/personalApi"
    
    # â˜… í”„ë¡¬í”„íŠ¸ ê°•í™”
    prompt = f"""
    ë‹¹ì‹ ì€ í¬ìŠ¤ì½” í“¨ì²˜ì—  ì„¤ë¹„ ìœ ì§€ë³´ìˆ˜ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
    ì‚¬ìš©ìëŠ” ì„¤ë¹„ì˜ ì•ŒëŒ ì½”ë“œë‚˜ ê³ ì¥ ì¦ìƒì— ëŒ€í•´ ë¬»ê³  ìˆìŠµë‹ˆë‹¤.
    
    ì•„ë˜ [ë§¤ë‰´ì–¼ ë‚´ìš©]ì„ ë¶„ì„í•˜ì—¬ ë‹µë³€í•˜ì„¸ìš”.
    - ë‚´ìš©ì´ í‘œ(Table) í˜•íƒœë¡œ ë˜ì–´ ìˆë‹¤ë©´ í–‰/ì—´ì„ ì£¼ì˜ ê¹Šê²Œ ì—°ê²°í•˜ì—¬ í•´ì„í•˜ì„¸ìš”.
    - 'ì•ŒëŒ ì½”ë“œ', 'ì›ì¸', 'ì¡°ì¹˜ ë°©ë²•'ì„ ëª…í™•íˆ êµ¬ë¶„í•´ì„œ ì„¤ëª…í•˜ì„¸ìš”.
    - ë‚´ìš©ì— ì—†ëŠ” ì‚¬ì‹¤ì€ ì§€ì–´ë‚´ì§€ ë§ˆì„¸ìš”.
    
    [ë§¤ë‰´ì–¼ ë‚´ìš©]
    {context}
    
    [ì§ˆë¬¸]
    {user_input}
    
    [ë‹µë³€ í˜•ì‹]
    1. ğŸš¨ ì¦ìƒ/ì•ŒëŒ ì˜ë¯¸: (ê°„ëµ ì„¤ëª…)
    2. ğŸ› ï¸ ì›ì¸ ë° ì¡°ì¹˜ ë°©ë²•: (ë²ˆí˜¸ ë§¤ê²¨ì„œ ìƒì„¸ ì„¤ëª…)
    3. ğŸ“„ ì°¸ê³  ë¬¸ì„œ: (íŒŒì¼ëª…, í˜ì´ì§€)
    """
    
    payload = {"messages": [{"role": "user", "content": prompt}], "model": "gpt-5-chat-latest"}
    headers = {"Authorization": f"Bearer {api_key}", "Content-Type": "application/json"}
    try:
        response = requests.post(url, headers=headers, data=json.dumps(payload))
        return response.text
    except Exception as e:
        return f"GPT Error: {str(e)}"

def scroll_to_bottom():
    js = """<script>
        var body = window.parent.document.querySelector(".main");
        if (body) { body.scrollTop = body.scrollHeight; }
    </script>"""
    components.html(js, height=0, width=0)

# --- [5. ì‚¬ì´ë“œë°” (ì—¬ê¸°ì— ì—ëŸ¬ ìˆ˜ì •ë¨)] ---
with st.sidebar:
    st.header("âš™ï¸ ì„¤ì •")
    file_list = [f for f in os.listdir(MANUAL_DIR) if f.endswith(".pdf")]
    search_options = ["ì „ì²´ ë§¤ë‰´ì–¼ ê²€ìƒ‰"] + file_list
    selected_manual = st.selectbox("ê²€ìƒ‰ ëŒ€ìƒ ì„ íƒ", search_options, index=0)
    
    st.divider()
    
    if "is_admin" not in st.session_state: st.session_state.is_admin = False
    
    # â˜… ì—ëŸ¬ í•´ê²°: key="admin_login_pw" ì¶”ê°€í•˜ì—¬ ê³ ìœ  ID ë¶€ì—¬
    if not st.session_state.is_admin:
        if st.text_input("ê´€ë¦¬ì ì•”í˜¸", type="password", key="admin_login_pw") == ADMIN_PASSWORD:
            st.session_state.is_admin = True
            st.rerun()
    
    if st.session_state.is_admin:
        st.success("ğŸ”“ ê´€ë¦¬ì ëª¨ë“œ")
        st.subheader("íŒŒì¼ ê´€ë¦¬")
        for f in file_list:
            c1, c2 = st.columns([0.8, 0.2])
            c1.text(f"{f}")
            if c2.button("x", key=f"del_{f}"): # keyì— íŒŒì¼ëª… ë¶™ì—¬ì„œ ê³ ìœ í™”
                os.remove(os.path.join(MANUAL_DIR, f))
                if os.path.exists(os.path.join(CACHE_DIR, f)):
                    shutil.rmtree(os.path.join(CACHE_DIR, f))
                st.rerun()
        
        st.markdown("---")
        # â˜… [ì´ˆê¸°í™” ë° ì¬í•™ìŠµ ë²„íŠ¼]
        if st.button("ğŸ”„ DB ì „ì²´ ì´ˆê¸°í™” ë° ì¬í•™ìŠµ", type="primary", use_container_width=True):
            with st.status("ë°ì´í„°ë² ì´ìŠ¤ ì¬êµ¬ì¶• ì¤‘...", expanded=True) as status:
                st.write("1. ê¸°ì¡´ ë°ì´í„° ì‚­ì œ ì¤‘...")
                if os.path.exists(CACHE_DIR): shutil.rmtree(CACHE_DIR)
                if os.path.exists(DB_PATH): shutil.rmtree(DB_PATH)
                os.makedirs(CACHE_DIR, exist_ok=True)
                
                st.write("2. ìƒˆë¡œìš´ ì„¤ì •(Chunk 1200)ìœ¼ë¡œ í•™ìŠµ ì‹œì‘...")
                update_vector_db()
                status.update(label="ì™„ë£Œ!", state="complete", expanded=False)
            
            st.success("ì¬í•™ìŠµ ì™„ë£Œ! ì´ì œ ì§ˆë¬¸í•´ë³´ì„¸ìš”.")
            time.sleep(1.5)
            st.rerun()
            
        if st.button("ğŸšª ë¡œê·¸ì•„ì›ƒ"):
            st.session_state.is_admin = False
            st.rerun()

    st.divider()
    if st.button("ğŸ§¹ ëŒ€í™” ë‚´ìš© ì§€ìš°ê¸°", use_container_width=True):
        st.session_state.messages = []
        st.rerun()

# --- [6. ë©”ì¸ ë¡œì§] ---
if "messages" not in st.session_state: st.session_state.messages = []

if len(st.session_state.messages) == 0:
    st.markdown("""
        <div style="text-align: center; margin-top: 15vh;">
            <div style="font-size: 5rem; margin-bottom: 20px;">ğŸ­</div>
            <h1 style="color: #005eb8;">POSCO FUTURE M<br>Smart Assistant</h1>
        </div>
    """, unsafe_allow_html=True)
else:
    for msg in st.session_state.messages:
        with st.chat_message(msg["role"]): st.markdown(msg["content"])

if prompt := st.chat_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”..."):
    st.session_state.messages.append({"role": "user", "content": prompt})
    st.rerun()

if st.session_state.messages and st.session_state.messages[-1]["role"] == "user":
    vectorstore = load_manual_db()
    
    if vectorstore:
        with st.chat_message("assistant"):
            with st.spinner(f"'{selected_manual}'ì—ì„œ ì •ë°€ ê²€ìƒ‰ ì¤‘..."):
                search_kwargs = {}
                if selected_manual != "ì „ì²´ ë§¤ë‰´ì–¼ ê²€ìƒ‰":
                    search_kwargs["filter"] = {"source": selected_manual}
                
                try:
                    # ê²€ìƒ‰ ë²”ìœ„ k=10
                    docs = vectorstore.similarity_search(st.session_state.messages[-1]["content"], k=10, **search_kwargs)
                except:
                    docs = []

                if not docs:
                    answer = f"âš ï¸ '{selected_manual}' ë‚´ì—ì„œ ê´€ë ¨ ë‚´ìš©ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
                    full_context = ""
                    sources = []
                else:
                    context_parts = []
                    sources = set()
                    for d in docs:
                        content = d.page_content 
                        src = d.metadata.get('source', 'Unknown')
                        page = d.metadata.get('page', 0)
                        context_parts.append(f"ğŸ“„ [íŒŒì¼: {src} | p.{page}]\n{content}")
                        sources.add(f"{src} (p.{page})")
                    full_context = "\n\n".join(context_parts)
                    answer = ask_posco_gpt(full_context, st.session_state.messages[-1]["content"])
                
                st.markdown(answer)
                if sources:
                    st.divider()
                    st.caption(f"**ğŸ“š ì°¸ì¡° ë¬¸ì„œ:** {', '.join(sources)}")
                    with st.expander("ğŸ” ì›ë¬¸ ë³´ê¸°"):
                        st.text_area("Context", value=full_context, height=200)
                
                st.session_state.messages.append({"role": "assistant", "content": answer})
                scroll_to_bottom()
    else:
        st.error("í•™ìŠµëœ DBê°€ ì—†ìŠµë‹ˆë‹¤. ê´€ë¦¬ì ë¡œê·¸ì¸ í›„ DBë¥¼ ì—…ë°ì´íŠ¸í•˜ì„¸ìš”.")
        st.session_state.messages.append({"role": "assistant", "content": "DBê°€ ì—†ìŠµë‹ˆë‹¤."})

st.markdown("<div style='height: 100px;'></div>", unsafe_allow_html=True)
if len(st.session_state.messages) > 0: scroll_to_bottom()
